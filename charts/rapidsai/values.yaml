# Default values for rapidsai.

service:
  image:
    version: "inseefrlab/rapidsai:cuda11.0-spark3.2.0"
    pullPolicy: IfNotPresent
    custom:
      enabled: false
      version: "inseefrlab/rapidsai:cuda11.0-spark3.2.0"
  
security:
  password: "changeme"
  networkPolicy: 
    enable: false
    from: 
    - ipBlock:
        cidr: 10.233.103.0/32
    - ipBlock:
        cidr: 10.233.111.0/32
  allowlist:
    enabled: true
    ip: "0.0.0.0/0"

init:
  standardInit: "https://git.lab.sspcloud.fr/innovation/plateforme-onyxia/services-ressources/-/raw/master/onyxia-init.sh"
  filename: "onyxia-init.sh"
  personalInit: ""
  personalInitArgs: ""

spark:
  sparkui: false
  configMapName: ""
  default: true
  config:
    spark.master: k8s://https://kubernetes.default.svc:443
    spark.kubernetes.authenticate.driver.serviceAccountName: '{{ include "library-chart.fullname" . }}'                
    spark.kubernetes.driver.pod.name: '{{ include "library-chart.fullname" . }}-0'
    spark.kubernetes.namespace: '{{ .Release.Namespace }}'
    spark.dynamicAllocation.enabled: "true"
    spark.dynamicAllocation.initialExecutors: "1"
    spark.dynamicAllocation.minExecutors: "1"
    spark.dynamicAllocation.maxExecutors: "10"
    spark.dynamicAllocation.executorAllocationRatio: "1"
    spark.dynamicAllocation.shuffleTracking.enabled: "true"
    spark.kubernetes.container.image: '{{ ternary .Values.service.image.custom.version .Values.service.image.version .Values.service.image.custom.enabled }}'
    spark.executor.resource.gpu.amount: "1"
    spark.task.resource.gpu.amount: "1"
    spark.executor.resource.gpu.discoveryScript: "/opt/spark/examples/src/main/scripts/getGpusResources.sh"
    spark.executor.resource.gpu.vendor: "nvidia.com"
    spark.rapids.sql.enabled: "true"
    spark.rapids.sql.incompatibleOps.enabled: "true"
    spark.plugins: "com.nvidia.spark.SQLPlugin"
    spark.rapids.force.caller.classloader: "false"

#active ou non la recherche d'un hiveMetastore dans le namespace
# see configmap-hive.yaml et helpers template
discovery:
  hive: true
  mlflow: true

hive:
  configMapName: ""

mlflow:
  configMapName: ""

coresite:
  configMapName: ""
  
s3:
  # Specifies whether a config map should be created
  enabled: true
  # The name of the configmap to use.
  # If not set and create is true, a name is generated using the fullname template
  configMapName: ""
  accessKeyId: ""
  endpoint: ""
  defaultRegion: ""
  secretAccessKey: ""
  sessionToken: ""


vault:
  # Specifies whether a config map should be created
  enabled: true
  # The name of the configmap to use.
  # If not set and create is true, a name is generated using the fullname template
  configMapName: ""
  token: ""
  url: ""
  mount: ""
  secret: ""
  directory: ""  

git:
  # Specifies whether a config map should be created
  enabled: true
  # The name of the configmap to use.
  # If not set and create is true, a name is generated using the fullname template
  configMapName: ""
  name: ""
  email: ""
  cache: ""

# This is a YAML-formatted file.
# Declare variables to be passed into your templates.
replicaCount: 1


imagePullSecrets: []
nameOverride: ""
fullnameOverride: ""

serviceAccount:
  # Specifies whether a service account should be created
  create: true
  # Annotations to add to the service account
  annotations: {}
  # The name of the service account to use.
  # If not set and create is true, a name is generated using the fullname template
  name: ""

persistence:
  enabled: true
  ## database data Persistent Volume Storage Class
  ## If defined, storageClassName: <storageClass>
  ## If set to "-", storageClassName: "", which disables dynamic provisioning
  ## If undefined (the default) or set to null, no storageClassName spec is
  ##   set, choosing the default provisioner.  (gp2 on AWS, standard on
  ##   GKE, AWS & OpenStack)
  ##
  # storageClass: "-"
  accessMode: ReadWriteOnce
  size: 10Gi
  mountPath: /rapids/work
  # existingClaim: ""

kubernetes:
  enabled: false
  role: "view"

podAnnotations: {}

podSecurityContext: {}
  # fsGroup: 2000

securityContext: {}
  # capabilities:
  #   drop:
  #   - ALL
  # readOnlyRootFilesystem: true
  # runAsNonRoot: true
  # runAsUser: 1000

networking:
  type: ClusterIP
  clusterIP: None
  rapidsai:
    port: 80
  sparkui:
    port: 4040

ingress:
  enabled: true
  tls: true
  annotations:
    kubernetes.io/ingress.class: nginx
    # kubernetes.io/tls-acme: "true"
  hostname: chart-example.local
  #  - secretName: chart-example-tls
  #    hosts:
  #      - chart-example.local

resources: {}
  # We usually recommend not to specify default resources and to leave this as a conscious
  # choice for the user. This also increases chances charts run on environments with little
  # resources, such as Minikube. If you do want to specify resources, uncomment the following
  # lines, adjust them as necessary, and remove the curly braces after 'resources:'.
  # limits:
  #   cpu: 100m
  #   memory: 128Mi
  # requests:
  #   cpu: 100m
  #   memory: 128Mi

autoscaling:
  enabled: false
  minReplicas: 1
  maxReplicas: 100
  targetCPUUtilizationPercentage: 80
  # targetMemoryUtilizationPercentage: 80

nodeSelector: {}

tolerations: []

affinity: {}

tags:
  enabled: true
  filtertag1: ""
  filtertag2: ""
  filtertag3: ""
